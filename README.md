Repo for testing/profiling encoder-decoder model (openai-whisper) serving performance.

1.

conda create --name "whisper_latency" python=3.10

2.

conda activate whisper_latency


3.

pip install -r requirements.txt

4.

run one of the latency measuring scripts with "python ..."
